{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load API key\n",
    "def read_api_key(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "REPLICATE_API_TOKE = read_api_key('../API_Key/REPLICATE_API_TOKEN.txt')\n",
    "OPENAI_API_KEY = read_api_key('../API_Key/OPENAI_API_KEY.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKE\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Local llama2\n",
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "llama2_chat = ChatOllama(model=\"llama2:13b-chat\")\n",
    "llama2_code = ChatOllama(model=\"codellama:7b-instruct\")\n",
    "\n",
    "# API\n",
    "from langchain.llms import Replicate\n",
    "\n",
    "# os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
    "replicate_id = \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\"\n",
    "llama2_chat_replicate = Replicate(\n",
    "    model=replicate_id, model_kwargs={\"temperature\": 0.01, \"max_length\": 500, \"top_p\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llama2_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Set MySQL and SQLite DB\n",
    "# from typing import Any, Dict, List, Tuple, Union\n",
    "# from langchain.utilities import SQLDatabase\n",
    "# import pymysql\n",
    "# KV = Dict[str, Any]\n",
    "# Query = Tuple[str, List]\n",
    "\n",
    "# class mySQL_DB:\n",
    "#     def __init__(self, host: str, port: int, user: str, password: str, database: str):\n",
    "#         conn = pymysql.connect(\n",
    "#             host=host,\n",
    "#             port=port,\n",
    "#             user=user,\n",
    "#             password=password,\n",
    "#             database=database,\n",
    "#             cursorclass=pymysql.cursors.DictCursor,\n",
    "#         )\n",
    "#         self.conn = conn\n",
    "#         self.database = database\n",
    "\n",
    "#     def get_cursor(self):\n",
    "#         return self.conn.cursor()\n",
    "    \n",
    "#     def run_query(self, query: str, args: List, ret_result: bool) -> Union[List[KV], int]:\n",
    "\n",
    "#         cur = self.get_cursor()\n",
    "#         count = cur.execute(query, args=args)\n",
    "#         if ret_result:\n",
    "#             return cur.fetchall()\n",
    "#         else:\n",
    "#             return count\n",
    "    \n",
    "#     def get_schema(self):\n",
    "#         \"\"\"\n",
    "#         Fetches all tables and their columns from a specified MySQL database.\n",
    "#         :return: Dictionary with table names as keys and list of columns as values\n",
    "#         \"\"\"\n",
    "#         connection = self.conn\n",
    "#         cursor = connection.cursor()\n",
    "\n",
    "#         # Fetch tables and columns\n",
    "#         query = \"\"\"\n",
    "#         SELECT \n",
    "#             TABLE_NAME, \n",
    "#             COLUMN_NAME \n",
    "#         FROM \n",
    "#             information_schema.COLUMNS \n",
    "#         WHERE \n",
    "#             TABLE_SCHEMA = %s\n",
    "#         ORDER BY \n",
    "#             TABLE_NAME, \n",
    "#             ORDINAL_POSITION;\n",
    "#         \"\"\"\n",
    "#         cursor.execute(query, (self.database,))\n",
    "\n",
    "#         # Process the results\n",
    "#         tables_columns = {}\n",
    "#         for table_name, column_name in cursor:\n",
    "#             if table_name not in tables_columns:\n",
    "#                 tables_columns[table_name] = []\n",
    "#             tables_columns[table_name].append(column_name)\n",
    "#         return tables_columns\n",
    "    \n",
    "# class SQLite_DB:\n",
    "#     def __init__(self, db_path: str):\n",
    "#         self.db = SQLDatabase.from_uri(db_path, sample_rows_in_table_info=0)\n",
    "    \n",
    "#     def get_schema(self):\n",
    "#         return self.db.get_table_info()\n",
    "    \n",
    "#     def run_query(self,query):\n",
    "#         return self.db.run(query)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Set up SQLite DB using the above classes\n",
    "from langchain.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./Chinook.db\", sample_rows_in_table_info=0)\n",
    "# db = SQLite_DB(\"sqlite:///./Chinook.db\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "def run_query(query):\n",
    "    print(\"running query\\n\", query)\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "prompt_llama2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Given an input question, convert it to a SQL query. No pre-amble.\"),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM Employee'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query\n",
      " SELECT COUNT(*) FROM Employee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are 8 employees.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query\n",
      " SELECT a.Name AS Artist, COUNT(il.InvoiceLineId) AS TotalSales\n",
      "FROM Artist a\n",
      "JOIN Album al ON a.ArtistId = al.ArtistId\n",
      "JOIN Track t ON al.AlbumId = t.AlbumId\n",
      "JOIN InvoiceLine il ON t.TrackId = il.TrackId\n",
      "GROUP BY a.Name\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 3;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The top 3 best-selling artists from the database are Iron Maiden with 140 total sales, U2 with 107 total sales, and Metallica with 91 total sales.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"What are the top 3 best-selling artists from the database?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now using llama2_chat\n",
    "\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "db = SQLDatabase.from_uri(\"sqlite:///nba_roster.db\", sample_rows_in_table_info=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT Team\\nFROM nba_roster\\nWHERE NAME = 'Klay Thompson';\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "template = \"\"\"Given an input question, convert it to a SQL query. No pre-amble. Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Chain to query with memory\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        history=RunnableLambda(lambda x: memory.load_memory_variables(x)[\"history\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def save(input_output):\n",
    "    output = {\"output\": input_output.pop(\"output\")}\n",
    "    memory.save_context(input_output, output)\n",
    "    return output[\"output\"]\n",
    "\n",
    "\n",
    "sql_response_memory = RunnablePassthrough.assign(output=sql_chain) | save\n",
    "sql_response_memory.invoke({\"question\": \"What team is Klay Thompson on?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='What team is Klay Thompson on?'), AIMessage(content=\"\\nSELECT Team\\nFROM nba_roster\\nWHERE NAME = 'Klay Thompson';\")]}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({\"question\": \"What team is Klay Thompson on?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query\n",
      " \n",
      "SELECT NAME, Jersey FROM nba_roster WHERE Team = (SELECT Team FROM nba_roster WHERE NAME = 'Klay Thompson');\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\nOther members of Klay Thompson's team are:\\n\\n* Stephen Curry (#30)\\n* Draymond Green (#23)\\n* JaMychal Green (#1)\\n* Andre Iguodala (#9)\\n* Trayce Jackson-Davis (NA)\\n* Cory Joseph (#18)\\n* Jonathan Kuminga (00)\\n* Anthony Lamb (#40)\\n* Kevon Looney (#5)\\n* Moses Moody (#4)\\n* Chris Paul (NA)\\n* Gary Payton II (#8)\\n* Brandin Podziemski (NA)\\n* Lester Quinones (#25)\\n* Dario Saric (#9)\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural language answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response_memory)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "\n",
    "full_chain.invoke({\"question\": \"What are the other members in his team?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='What team is Klay Thompson on?'), AIMessage(content=\"\\nSELECT Team FROM nba_roster WHERE NAME = 'Klay Thompson';\"), HumanMessage(content='What is his salary?'), AIMessage(content=\"\\nSELECT SALARY FROM nba_roster WHERE NAME = 'Klay Thompson';\")]}\n",
      "first=RunnableAssign(mapper={\n",
      "  output: RunnableAssign(mapper={\n",
      "            schema: RunnableLambda(get_schema),\n",
      "            history: RunnableLambda(lambda x: memory.load_memory_variables(x)['history'])\n",
      "          })\n",
      "          | ChatPromptTemplate(input_variables=['history', 'question', 'schema'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['schema'], template=\"Given an input question, convert it to a SQL query. No pre-amble. Based on the table schema below, write a SQL query that would answer the user's question:\\n{schema}\\n\")), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])\n",
      "          | RunnableBinding(bound=ChatOllama(model='llama2:13b-chat'), kwargs={'stop': ['\\nSQLResult:']})\n",
      "          | StrOutputParser()\n",
      "}) last=RunnableLambda(save)\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({\"question\": \"Who else are in his team?\"}))\n",
    "print(sql_response_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query\n",
      " \n",
      "SELECT SALARY FROM nba_roster WHERE NAME = 'Klay Thompson';\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Natural language response:\\n\\nKlay Thompson's salary is $43,219,440.\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "template = \"\"\"Given an input question, convert it to a SQL query. No pre-amble. Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        history=RunnableLambda(lambda x: memory.load_memory_variables(x)[\"history\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    " \n",
    "\n",
    "def save(input_output):\n",
    "    output = {\"output\": input_output.pop(\"output\")}\n",
    "    memory.save_context(input_output, output)\n",
    "    return output[\"output\"]\n",
    "\n",
    "\n",
    "sql_response_memory = RunnablePassthrough.assign(output=sql_chain) | save\n",
    "sql_response_memory.invoke({\"question\": \"What team is Klay Thompson on?\"})\n",
    "\n",
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural language answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response_memory)\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")\n",
    "\n",
    "full_chain.invoke({\"question\": \"What is his salary?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}